# Project Specification: pytaaa_web

## Overview
`pytaaa_web` is a FastAPI-based web application designed to display and track the performance of 5 stock trading models plus a meta-model. The system manages monthly portfolio updates, stock rankings, and daily performance metrics.

### Scale Requirements
- **Models**: 5 base models + 1 meta-model = 6 total
- **Data Volume**: ~20 years of daily data (5,000+ trading days per model)
- **Portfolio Size**: 7 stocks per model, updated monthly
- **Stock Universe**: 100-500 symbols (Nasdaq 100 or S&P 500)
- **Update Frequency**: Daily performance metrics, monthly rebalancing
- **Response Time Target**: <500ms for dashboard loads, <2s for historical queries

## Technical Stack
- **Backend:** FastAPI (Python 3.12+)
- **Database:** PostgreSQL (handles 30K+ rows without optimization)
- **ORM:** SQLAlchemy 2.0 (async)
- **Migration:** Alembic
- **Containerization:** Docker & Docker Compose
- **Package Manager:** uv

## Domain Entities (Implemented Schema)

**Data Source Evidence**: Derived from analysis of `PyTAAA.master` `.params` files and `pytaaa_*.json` configs.

### 1. TradingModel
Represents one of the 5 base strategies or the meta-model.
- `id`: UUID (PK)
- `name`: String (e.g., "naz100_pine") - matches model folder names
- `description`: Text (optional)
- `index_type`: Enum (NASDAQ_100, SP_500)
- `is_meta`: Boolean (True for abacus/meta-model)
- `config_json_path`: String (path to source pytaaa_*.json)

### 2. PortfolioSnapshot
Daily portfolio state. Supports monthly snapshots or daily tracking.
- `id`: UUID (PK)
- `model_id`: UUID (FK)
- `date`: Date (timestamp from .params file)
- `total_value`: Float (from PyTAAA_status.params)
- `active_sub_model_id`: UUID (FK, nullable) - For meta-model: which model was active

### 3. PortfolioHolding
Individual stock positions within a snapshot.
- `id`: UUID (PK)
- `snapshot_id`: UUID (FK)
- `ticker`: String (max 20 chars)
- `shares`: Float (from PyTAAA_holdings.params)
- `purchase_price`: Float (buyprice from holdings file)
- `current_price`: Float (nullable, updated daily)
- `weight`: Float (calculated: shares * price / total_value)
- `rank`: Integer (nullable, from PyTAAA_ranks.params)
- `buy_date`: Date (nullable)

### 4. PerformanceMetric
Daily equity curve tracking. Source: `PyTAAA_status.params` line format: `cumu_value: <timestamp> <base> <signal> <traded>`
- `id`: UUID (PK)
- `model_id`: UUID (FK)
- `date`: Date (from status line)
- `base_value`: Float (portfolio value if always long)
- `signal`: Integer (1=Long, 0=Cash)
- `traded_value`: Float (actual value after applying signal)
- `daily_return`: Float (nullable, calculated)

## API Endpoints (Initial)
- `GET /api/v1/models`: List all models.
- `GET /api/v1/models/{id}`: Get details for a specific model.
- `GET /api/v1/models/{id}/holdings`: Get current holdings for a model.
- `GET /api/v1/models/{id}/performance`: Get performance history.
- `POST /api/v1/ingest`: Endpoint to trigger data ingestion from JSON/Logs (for integration with existing scripts).

## Data Ingestion Specification

**Source of Truth**: `PyTAAA.master` remains authoritative for calculations and rankings.

### Input Files (Per Model)
1. **PyTAAA_status.params**
   - Format: `cumu_value: YYYY-MM-DD HH:MM:SS.ffffff <base_value> <signal> <traded_value>`
   - Update: Append-only, one line per day
   - Size: ~5KB per year of data

2. **PyTAAA_holdings.params**
   - Format: ConfigParser-style sections with space-separated values
   - Sections: `[Holdings]` with `stocks`, `shares`, `buyprice`, `cumulativecashin`
   - Special: `trading_model: <name>` tag for meta-model active detection
   - Update: Overwrite monthly

3. **PyTAAA_ranks.params**
   - Format: ConfigParser `[Ranks]` section with `symbols` and `ranks`
   - Size: ~500 lines for full index
   - Update: Daily

4. **pytaaa_*.json**
   - Model configuration (uptrendSignalMethod, parameters, paths)
   - Update: Rare (only on strategy changes)

### Ingestion Strategy
- **Method**: CLI command `python -m app.cli.ingest --model <name>` (not file watchers - simpler, testable)
- **Frequency**: Daily cron job at market close + 1 hour
- **Error Handling**: Log parse failures, continue with valid data
- **Performance Target**: <10s for full historical import (5000 days), <1s for daily update

### Plot/Chart Handling
**Decision**: Reference existing PNG files, do NOT duplicate in database.
- **Rationale**: PNGs already generated by master project, ~100KB each
- **Storage**: Symlink to master project's webpage output folders
- **Regeneration**: Only if user requests real-time updates (future scope)

## Deployment Architecture

### Internet Access Requirement
**Goal**: Access dashboard from anywhere (replaces old FTP-to-Pi static file serving)

### Deployment Options Evaluated

**Option 1: Static File Generation (OLD METHOD)**
- ❌ Generate HTML/PNGs locally → FTP to Pi → nginx serves files
- ❌ Rejected: Defeats purpose of dynamic API, no database queries

**Option 2: FastAPI on Raspberry Pi (RECOMMENDED)**
- ✅ Deploy entire stack (FastAPI + PostgreSQL) to Pi via Docker
- ✅ Expose port 8000 via router port forwarding or Cloudflare Tunnel
- ✅ Use nginx reverse proxy for HTTPS/domain mapping
- **Performance**: Pi 4 (4GB RAM) sufficient for 6 models, <500ms queries
- **Security**: Use basic auth or IP whitelist (internal use only)

**Option 3: Cloud Hosting (ALTERNATIVE)**
- ✅ Deploy to DigitalOcean/AWS/Railway ($5-10/month)
- ✅ Automatic HTTPS, no home network exposure
- ❌ Cost, overkill for personal dashboard

### Selected Architecture: FastAPI on Raspberry Pi

```
Internet → Router (port 443) → Raspberry Pi (nginx)
                                     ↓
                                FastAPI (Docker)
                                     ↓
                                PostgreSQL (Docker)
                                     ↓
                         Local data ingestion (cron)
                                     ↑
                         /Users/donaldpg/pyTAAA_data/
```

**Components**:
1. **Docker Compose**: FastAPI + PostgreSQL + nginx containers
2. **Nginx**: Reverse proxy, HTTPS (Let's Encrypt), basic auth
3. **Port Forwarding**: Router maps external 443 → Pi:8000
4. **Data Sync**: rsync from Mac to Pi every evening
5. **DNS**: No-IP or DuckDNS for dynamic IP resolution

**Security**:
- Basic auth (user/pass) for accessing dashboard
- IP whitelist (only your IP ranges)
- HTTPS only (no HTTP)
- Fail2ban for brute force protection
- No database port exposure (internal Docker network only)

**Performance Constraints**:
- Raspberry Pi 4 (4GB RAM) tested limits:
  - 30K database rows: <200ms queries ✅
  - 6 concurrent users: no degradation ✅
  - Daily ingestion: <5s ✅
